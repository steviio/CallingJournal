# =============================================================================
# CallingJournal Backend Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# All variables without defaults are REQUIRED.
#
# SECURITY WARNING: Never commit your .env file to version control!
# =============================================================================

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
# APP_NAME: Display name for the application (used in logs and API docs)
APP_NAME=CallingJournal

# APP_VERSION: Current application version
APP_VERSION=1.0.0

# ENVIRONMENT: Runtime environment (development, staging, production)
# - development: Enables debug mode, detailed error messages
# - production: Disables debug features, optimized for performance
ENVIRONMENT=development

# DEBUG: Enable debug mode (true/false)
# - true: Shows detailed error traces, enables /docs endpoint
# - false: Production-safe error handling
DEBUG=true

# API_HOST: Host address to bind the server
# - 0.0.0.0: Accept connections from any IP (required for Docker/containers)
# - 127.0.0.1: Only accept local connections
API_HOST=0.0.0.0

# API_PORT: Port number for the API server
API_PORT=8000

# -----------------------------------------------------------------------------
# Database Configuration (PostgreSQL)
# -----------------------------------------------------------------------------
# The application uses PostgreSQL with async support via asyncpg.
# For local development, you can use Docker:
#   docker run -d --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=password postgres:15

# DB_HOST: PostgreSQL server hostname or IP address
DB_HOST=localhost

# DB_PORT: PostgreSQL server port (default: 5432)
DB_PORT=5432

# DB_NAME: Database name (will be created if it doesn't exist)
DB_NAME=calling_journal

# DB_USER: Database username with read/write permissions
DB_USER=postgres

# DB_PASSWORD: Database password (REQUIRED - use a strong password in production)
DB_PASSWORD=your-database-password

# -----------------------------------------------------------------------------
# JWT Authentication
# -----------------------------------------------------------------------------
# JWT tokens are used for API authentication. Generate a secure secret key:
#   python -c "import secrets; print(secrets.token_urlsafe(32))"

# SECRET_KEY: Secret key for signing JWT tokens (REQUIRED)
# IMPORTANT: Use a unique, random string in production!
SECRET_KEY=your-secret-key-change-this-in-production

# ALGORITHM: JWT signing algorithm (default: HS256)
# Options: HS256, HS384, HS512
ALGORITHM=HS256

# ACCESS_TOKEN_EXPIRE_MINUTES: Token validity period in minutes
# Default: 1440 (24 hours)
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# -----------------------------------------------------------------------------
# LLM Configuration - OpenAI
# -----------------------------------------------------------------------------
# OpenAI is used for conversation summarization, entity extraction, and chat.
# Get your API key: https://platform.openai.com/api-keys

# OPENAI_API_KEY: Your OpenAI API key (starts with "sk-")
OPENAI_API_KEY=your-openai-api-key

# OPENAI_MODEL: Model for chat and summarization
# Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
OPENAI_MODEL=gpt-4-turbo-preview

# OPENAI_EMBEDDING_MODEL: Model for text embeddings (used in vector search)
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# LLM Configuration - Anthropic (Optional)
# -----------------------------------------------------------------------------
# Anthropic Claude can be used as an alternative to OpenAI.
# Get your API key: https://console.anthropic.com/

# ANTHROPIC_API_KEY: Your Anthropic API key
ANTHROPIC_API_KEY=your-anthropic-api-key

# ANTHROPIC_MODEL: Claude model to use
# Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
ANTHROPIC_MODEL=claude-3-opus-20240229

# -----------------------------------------------------------------------------
# Vector Database - Pinecone (Optional)
# -----------------------------------------------------------------------------
# Pinecone is used for semantic search in the knowledge base.
# Get your API key: https://www.pinecone.io/

# PINECONE_API_KEY: Your Pinecone API key
PINECONE_API_KEY=your-pinecone-api-key

# PINECONE_INDEX_NAME: Name of the Pinecone index to use
# The index will be created automatically if it doesn't exist
PINECONE_INDEX_NAME=journal-embeddings

# -----------------------------------------------------------------------------
# Phone Service - Twilio (Required for call functionality)
# -----------------------------------------------------------------------------
# Twilio handles outbound calls and webhooks.
# Get your credentials: https://console.twilio.com/

# TWILIO_ACCOUNT_SID: Your Twilio Account SID (starts with "AC")
TWILIO_ACCOUNT_SID=your-twilio-account-sid

# TWILIO_AUTH_TOKEN: Your Twilio Auth Token
TWILIO_AUTH_TOKEN=your-twilio-auth-token

# TWILIO_PHONE_NUMBER: Your Twilio phone number in E.164 format
# Example: +14155551234
TWILIO_PHONE_NUMBER=your-twilio-phone-number

# -----------------------------------------------------------------------------
# Transcription - Local Whisper (Offline)
# -----------------------------------------------------------------------------
# OpenAI Whisper runs locally for batch transcription of recordings.
# No API key required - models are downloaded automatically.

# WHISPER_MODEL: Whisper model size
# Options (speed vs accuracy tradeoff):
# - tiny: Fastest, lowest accuracy (~1GB VRAM)
# - base: Good balance for development (~1GB VRAM)
# - small: Better accuracy (~2GB VRAM)
# - medium: High accuracy (~5GB VRAM)
# - large: Best accuracy (~10GB VRAM)
WHISPER_MODEL=base

# -----------------------------------------------------------------------------
# Transcription - Deepgram (Real-time Streaming)
# -----------------------------------------------------------------------------
# Deepgram provides real-time streaming transcription with VAD.
# Get your API key: https://console.deepgram.com/

# DEEPGRAM_API_KEY: Your Deepgram API key
DEEPGRAM_API_KEY=your-deepgram-api-key

# DEEPGRAM_MODEL: Transcription model
# Options: nova-3 (recommended), nova-2, whisper
DEEPGRAM_MODEL=nova-3

# DEEPGRAM_LANGUAGE: Language code for transcription
# Options: en (English), es (Spanish), fr (French), etc.
DEEPGRAM_LANGUAGE=en

# DEEPGRAM_ENCODING: Audio encoding format (must match Twilio stream)
# Options: mulaw (Twilio default), linear16
DEEPGRAM_ENCODING=mulaw

# DEEPGRAM_SAMPLE_RATE: Audio sample rate in Hz (must match Twilio stream)
# Twilio Media Streams use 8000 Hz
DEEPGRAM_SAMPLE_RATE=8000

# DEEPGRAM_CHANNELS: Number of audio channels
# Twilio Media Streams are mono (1 channel)
DEEPGRAM_CHANNELS=1

# DEEPGRAM_ENDPOINTING: Silence duration (ms) to detect end of utterance
# Lower values = faster response, higher values = more complete sentences
# Recommended: 300-800ms
DEEPGRAM_ENDPOINTING=500

# -----------------------------------------------------------------------------
# Redis Configuration (Required for Celery task queue)
# -----------------------------------------------------------------------------
# Redis is used as the message broker for background tasks.
# For local development, you can use Docker:
#   docker run -d --name redis -p 6379:6379 redis:7

# REDIS_URL: Redis connection URL
# Format: redis://[username:password@]host:port/db_number
REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# File Storage Paths
# -----------------------------------------------------------------------------
# Directories for storing application data. Paths are relative to the
# backend directory unless absolute paths are specified.

# AUDIO_STORAGE_PATH: Directory for downloaded audio recordings
AUDIO_STORAGE_PATH=./data/audio

# LOG_STORAGE_PATH: Directory for application logs
LOG_STORAGE_PATH=./data/logs

# JOURNAL_STORAGE_PATH: Directory for exported journal files
JOURNAL_STORAGE_PATH=./data/journals

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------

# LOG_LEVEL: Minimum log level to output
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# LOG_FILE: Path to the application log file
LOG_FILE=./logs/app.log

# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# Cross-Origin Resource Sharing settings for frontend access.

# CORS_ORIGINS: JSON array of allowed origins
# Add your frontend URL(s) here for production
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]