# =============================================================================
# CallingJournal Backend Configuration
# =============================================================================
#
# INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in the required values (marked with REQUIRED)
# 3. Adjust optional values as needed
#
# All configuration is loaded from this file. The application will fail to
# start if required variables are missing.
#
# SECURITY WARNING: Never commit your .env file to version control!
#
# =============================================================================

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------

# APP_NAME: Display name for the application (used in logs and API docs)
APP_NAME=CallingJournal

# APP_VERSION: Current application version
APP_VERSION=1.0.0

# ENVIRONMENT: Runtime environment
# Options: development, staging, production
ENVIRONMENT=development

# DEBUG: Enable debug mode
# - true: Shows detailed error traces, enables /docs endpoint
# - false: Production-safe error handling
DEBUG=true

# API_HOST: Host address to bind the server
# - 0.0.0.0: Accept connections from any IP (required for Docker/containers)
# - 127.0.0.1: Only accept local connections
API_HOST=0.0.0.0

# API_PORT: Port number for the API server
API_PORT=8000

# -----------------------------------------------------------------------------
# Database Configuration (PostgreSQL) - REQUIRED
# -----------------------------------------------------------------------------
# The application uses PostgreSQL with async support via asyncpg.
#
# Quick start with Docker:
#   docker run -d --name postgres -p 5432:5432 \
#     -e POSTGRES_USER=postgres \
#     -e POSTGRES_PASSWORD=postgres \
#     -e POSTGRES_DB=calling_journal \
#     postgres:15

# DB_HOST: PostgreSQL server hostname or IP address
DB_HOST=localhost

# DB_PORT: PostgreSQL server port
DB_PORT=5432

# DB_NAME: Database name
DB_NAME=calling_journal

# DB_USER: Database username (REQUIRED)
DB_USER=postgres

# DB_PASSWORD: Database password (REQUIRED - use a strong password in production)
DB_PASSWORD=postgres

# -----------------------------------------------------------------------------
# JWT Authentication - REQUIRED
# -----------------------------------------------------------------------------
# Generate a secure secret key:
#   python -c "import secrets; print(secrets.token_urlsafe(32))"

# SECRET_KEY: Secret key for signing JWT tokens (REQUIRED)
# IMPORTANT: Change this to a unique, random string in production!
SECRET_KEY=change-this-to-a-secure-random-string

# ALGORITHM: JWT signing algorithm
# Options: HS256, HS384, HS512
ALGORITHM=HS256

# ACCESS_TOKEN_EXPIRE_MINUTES: Token validity period in minutes
# Default: 1440 (24 hours)
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
# Choose which LLM provider to use. Only configure the provider you select.

# LLM_PROVIDER: Which LLM provider to use (REQUIRED)
# Options: openai, anthropic, openrouter
LLM_PROVIDER=openai

# -----------------------------------------------------------------------------
# OpenAI Configuration (when LLM_PROVIDER=openai)
# -----------------------------------------------------------------------------
# Get your API key: https://platform.openai.com/api-keys

# OPENAI_API_KEY: Your OpenAI API key (starts with "sk-")
# Leave empty if not using OpenAI
OPENAI_API_KEY=

# OPENAI_MODEL: Model for chat and summarization
# Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo, gpt-4o, gpt-4o-mini
OPENAI_MODEL=gpt-4-turbo-preview

# OPENAI_EMBEDDING_MODEL: Model for text embeddings (vector search)
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# Anthropic Configuration (when LLM_PROVIDER=anthropic)
# -----------------------------------------------------------------------------
# Get your API key: https://console.anthropic.com/

# ANTHROPIC_API_KEY: Your Anthropic API key
# Leave empty if not using Anthropic
ANTHROPIC_API_KEY=

# ANTHROPIC_MODEL: Claude model to use
# Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
#          claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# -----------------------------------------------------------------------------
# OpenRouter Configuration (when LLM_PROVIDER=openrouter)
# -----------------------------------------------------------------------------
# OpenRouter provides access to 100+ models through a unified API.
# Get your API key: https://openrouter.ai/keys
# Browse models: https://openrouter.ai/models

# OPENROUTER_API_KEY: Your OpenRouter API key
# Leave empty if not using OpenRouter
OPENROUTER_API_KEY=

# OPENROUTER_MODEL: Model to use (format: provider/model-name)
# Popular options:
#   openai/gpt-4-turbo, openai/gpt-4o, openai/gpt-4o-mini
#   anthropic/claude-3.5-sonnet, anthropic/claude-3-opus
#   google/gemini-pro-1.5, google/gemini-flash-1.5
#   meta-llama/llama-3.1-70b-instruct, meta-llama/llama-3.1-405b-instruct
#   mistralai/mistral-large, mistralai/mixtral-8x22b-instruct
#   deepseek/deepseek-chat, deepseek/deepseek-coder
OPENROUTER_MODEL=openai/gpt-4-turbo

# OPENROUTER_SITE_URL: Your site URL (optional, for OpenRouter analytics)
OPENROUTER_SITE_URL=

# OPENROUTER_APP_NAME: Your app name (optional, for OpenRouter analytics)
OPENROUTER_APP_NAME=CallingJournal

# -----------------------------------------------------------------------------
# Vector Database - Pinecone (Optional)
# -----------------------------------------------------------------------------
# Pinecone is used for semantic search in the knowledge base.
# Get your API key: https://www.pinecone.io/
# Leave empty to disable vector search features.

# PINECONE_API_KEY: Your Pinecone API key
PINECONE_API_KEY=

# PINECONE_INDEX_NAME: Name of the Pinecone index
PINECONE_INDEX_NAME=journal-embeddings

# -----------------------------------------------------------------------------
# Phone Service - Twilio (Required for call functionality)
# -----------------------------------------------------------------------------
# Twilio handles outbound calls and webhooks.
# Get your credentials: https://console.twilio.com/

# TWILIO_ACCOUNT_SID: Your Twilio Account SID (starts with "AC")
TWILIO_ACCOUNT_SID=

# TWILIO_AUTH_TOKEN: Your Twilio Auth Token
TWILIO_AUTH_TOKEN=

# TWILIO_PHONE_NUMBER: Your Twilio phone number in E.164 format
# Example: +14155551234
TWILIO_PHONE_NUMBER=

# -----------------------------------------------------------------------------
# Transcription - Whisper (Local/Offline)
# -----------------------------------------------------------------------------
# OpenAI Whisper runs locally for batch transcription.
# No API key required - models download automatically on first use.

# WHISPER_MODEL: Whisper model size (speed vs accuracy tradeoff)
# Options:
#   tiny   - Fastest, lowest accuracy (~1GB VRAM)
#   base   - Good balance for development (~1GB VRAM)
#   small  - Better accuracy (~2GB VRAM)
#   medium - High accuracy (~5GB VRAM)
#   large  - Best accuracy (~10GB VRAM)
WHISPER_MODEL=base

# -----------------------------------------------------------------------------
# Transcription - Deepgram (Real-time Streaming)
# -----------------------------------------------------------------------------
# Deepgram provides real-time streaming transcription with VAD.
# Get your API key: https://console.deepgram.com/

# DEEPGRAM_API_KEY: Your Deepgram API key
DEEPGRAM_API_KEY=

# DEEPGRAM_MODEL: Transcription model
# Options: nova-3 (recommended), nova-2, whisper
DEEPGRAM_MODEL=nova-3

# DEEPGRAM_LANGUAGE: Language code for transcription
# Options: en (English), es (Spanish), fr (French), de (German), etc.
DEEPGRAM_LANGUAGE=en

# DEEPGRAM_ENCODING: Audio encoding format
# Must match Twilio stream format. Options: mulaw (Twilio default), linear16
DEEPGRAM_ENCODING=mulaw

# DEEPGRAM_SAMPLE_RATE: Audio sample rate in Hz
# Twilio Media Streams use 8000 Hz
DEEPGRAM_SAMPLE_RATE=8000

# DEEPGRAM_CHANNELS: Number of audio channels
# Twilio Media Streams are mono (1 channel)
DEEPGRAM_CHANNELS=1

# DEEPGRAM_ENDPOINTING: Silence duration (ms) to detect end of utterance
# Lower = faster response, Higher = more complete sentences
# Recommended: 300-800ms
DEEPGRAM_ENDPOINTING=500

# -----------------------------------------------------------------------------
# Redis Configuration
# -----------------------------------------------------------------------------
# Redis is used as the message broker for Celery background tasks.
#
# Quick start with Docker:
#   docker run -d --name redis -p 6379:6379 redis:7

# REDIS_URL: Redis connection URL
# Format: redis://[username:password@]host:port/db_number
REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# File Storage Paths
# -----------------------------------------------------------------------------
# Directories for storing application data.
# Paths are relative to the backend directory unless absolute paths are used.

# AUDIO_STORAGE_PATH: Directory for downloaded audio recordings
AUDIO_STORAGE_PATH=./data/audio

# LOG_STORAGE_PATH: Directory for application logs
LOG_STORAGE_PATH=./data/logs

# JOURNAL_STORAGE_PATH: Directory for exported journal files
JOURNAL_STORAGE_PATH=./data/journals

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------

# LOG_LEVEL: Minimum log level to output
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# LOG_FILE: Path to the application log file
LOG_FILE=./logs/app.log

# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# Cross-Origin Resource Sharing settings for frontend access.

# CORS_ORIGINS: JSON array of allowed origins
# Add your frontend URL(s) here. Use ["*"] to allow all origins (not recommended for production)
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]